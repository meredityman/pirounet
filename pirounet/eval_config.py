"""
Configuration parameters for evaluation of a model.
Works in conjunction with the web labeling app (for blind labeling and comparison of labels.)
"""
import default_config
import torch

run_name = "run2"
# run_name = "testing_npy_creation"

##########################################################
# CUDA device for evaluation

device = default_config.device
##########################################################
# Tiling hyperparameters

step_size = [0.1, 0.2, 0.4]
# height/width of tiles for labels 0, 1, 2

dances_per_tile = [3, 3, 1]
# minimum dances required to be in a high density neighborhood for labels 0, 1, 2

density_thresh = [0.8, 0.75, 0.75]
# minimum percentage of dances required to share the label for labels 0, 1, 2

##########################################################
# Data dimensions

input_dim = default_config.input_dim
label_dim = default_config.label_dim
seq_len = default_config.seq_len
latent_dim = default_config.latent_dim

##########################################################
# Run that is evaluated

# load_from_checkpoint = default_config.load_from_checkpoint
# load_from_checkpoint = "checkpoint_pirounet_dance"
load_from_checkpoint = "ckpt-test1-499"
# load_from_checkpoint = "checkpoint_pirounet_watch"

##########################################################
# Evaluation hyperparameters

stat_sampling_size = 1
# how many iterations to bootstrap quantitative metrics

num_gen_cond_lab = 2
# how many sequences to conditionally generate per label for evaluation by quantiative metrics

num_random_artifacts = 2
# how many artifacts (animations) to save during random generation

num_cond_artifacts_per_lab = 2
# how many artifacts (animations) to save per label during conditional generation

##########################################################
# Desired immediate metrics

npy_output = False # True

# quali_gen_metrics = False
# quali_recon_metrics = False
# quanti_gen_recon_metrics = False
# generate_for_blind_labeling = False
# plot_classification_accuracy = False
# plot_latent_space = False
# test_entanglement = False

quali_gen_metrics = True
quali_recon_metrics = True
quanti_gen_recon_metrics = True
generate_for_blind_labeling = True
plot_classification_accuracy = True
plot_latent_space = True
test_entanglement = True

##########################################################
# Recognition accuracy metric
# Only run once labeler has labeled blindly generated sequences.

human_labels = "data/labels_shuffled_neighb.csv"
# human made labels, exported from web labeling app.

pirounet_labels = "data/shuffled_labels_variations.npy"
# labels associated to sequences generated by PirouNet, saved in 
# your_results_folder/to_be_labeled/labels_{eval_config.load_from_checkpoint}.npy"

plot_recognition_accuracy = False
